# Infraestrutura AWS - Teste TÃ©cnico Letrus

Este projeto provisiona uma infraestrutura completa na AWS para pipelines de dados, incluindo:

- **S3 Buckets**: Armazenamento de dados brutos e transformados (âœ… FREE TIER)
- **RDS PostgreSQL**: Banco de dados gerenciado (âœ… FREE TIER: db.t3.micro, 20GB)
- **AWS Glue**: Jobs e Crawlers para processamento de dados (otimizado: 0.5 DPU)
- **Bastion Host**: EC2 para acesso seguro ao RDS (âœ… FREE TIER: t3.micro)
- **VPC**: 2 AZs, 1 NAT Gateway, VPC Endpoint S3 (otimizado para dev)
- **IAM**: Roles e polÃ­ticas com princÃ­pio de menor privilÃ©gio

## Arquitetura

![Arquitetura do Pipeline ETL](docs/images/architecture-diagram.png)

## Estrutura do Projeto

```
.
â”œâ”€â”€ modules/              # MÃ³dulos Terraform
â”‚   â”œâ”€â”€ s3/              # Buckets S3 (raw, processed, scripts)
â”‚   â”œâ”€â”€ aurora/          # Aurora PostgreSQL cluster
â”‚   â”œâ”€â”€ glue/            # Glue Jobs e Crawlers
â”‚   â”œâ”€â”€ iam/             # IAM Roles e Policies
â”‚   â”œâ”€â”€ vpc/             # VPC e subnets
â”‚   â””â”€â”€ bastion/         # Bastion Host para acesso ao Aurora
â”œâ”€â”€ scripts/             # Scripts Python e Bash
â”‚   â”œâ”€â”€ glue_jobs/       # Scripts Glue e SQL
â”‚   â”‚   â”œâ”€â”€ etl_pipeline.py
â”‚   â”‚   â”œâ”€â”€ create_rds_tables.sql      # âœ… Renomeado de create_aurora_tables.sql
â”‚   â”‚   â””â”€â”€ analytics_queries.sql
â”‚   â”œâ”€â”€ generate_synthetic_data.py
â”‚   â”œâ”€â”€ upload_to_s3.py
â”‚   â”œâ”€â”€ run_pipeline.sh
â”‚   â””â”€â”€ create_rds_tables.sh           # âœ… Renomeado de create_aurora_tables.sh
â”œâ”€â”€ main.tf              # ConfiguraÃ§Ã£o principal
â”œâ”€â”€ variables.tf         # VariÃ¡veis
â”œâ”€â”€ outputs.tf           # Outputs
â”œâ”€â”€ terraform.tfvars            # Valores das variÃ¡veis (nÃ£o versionado)
â”œâ”€â”€ FREE_TIER_OPTIMIZATION.md   # ðŸŽ¯ OtimizaÃ§Ã£o Free Tier e custos mÃ­nimos
â”œâ”€â”€ COST_OPTIMIZATION.md        # OtimizaÃ§Ã£o de VPC (AZs e NAT)
â”œâ”€â”€ ANALYTICS_GUIDE.md          # Guia de queries analÃ­ticas
â””â”€â”€ README.md                   # Este arquivo
```

## ðŸ’° OtimizaÃ§Ã£o de Custos

Este projeto implementa **otimizaÃ§Ã£o AGRESSIVA para FREE TIER e custos mÃ­nimos**:

### ðŸŽ¯ OtimizaÃ§Ã£o Free Tier (Atual)
| Item | ConfiguraÃ§Ã£o | Status |
|------|--------------|--------|
| **RDS** | db.t3.micro, 20GB | âœ… FREE TIER |
| **Bastion** | EC2 t3.micro | âœ… FREE TIER |
| **S3** | <5GB, lifecycle agressivo | âœ… FREE TIER |
| **Glue** | 2 DPU (2 Ã— G.1X) | Otimizado |
| **VPC Endpoint S3** | Gateway | âœ… GRÃTIS |
| **Custo Total** | ~$35-50/mÃªs | **60-70% economia** |

ðŸ“– **[Veja detalhes completos em FREE_TIER_OPTIMIZATION.md](FREE_TIER_OPTIMIZATION.md)**

### ðŸ—ï¸ OtimizaÃ§Ã£o VPC por Ambiente
| Ambiente | AZs | NAT Gateways | Custo VPC/mÃªs |
|----------|-----|--------------|---------------|
| **Dev** | 2 | 1 | ~$35 |
| **Prod** | 3 | 3 | ~$100 |

ðŸ“– **[Veja detalhes em COST_OPTIMIZATION.md](COST_OPTIMIZATION.md)**

**âœ… Economia anual estimada em dev: ~$1,392**

Para detalhes completos sobre as otimizaÃ§Ãµes, veja **[COST_OPTIMIZATION.md](COST_OPTIMIZATION.md)**

## PrÃ©-requisitos

- Terraform >= 1.0
- AWS CLI configurado
- Credenciais AWS configuradas (via AWS CLI, variÃ¡veis de ambiente ou IAM Role)

## ConfiguraÃ§Ã£o Inicial

### 1. Clone o repositÃ³rio

### 2. Configure as variÃ¡veis do Terraform

```bash
cp terraform.tfvars.example terraform.tfvars
```

Edite `terraform.tfvars` com suas configuraÃ§Ãµes especÃ­ficas.

### 3. Provisione a infraestrutura

```bash
# Inicialize o Terraform
terraform init

# Revise o plano de execuÃ§Ã£o
terraform plan

# Aplique a infraestrutura
terraform apply
```

### 4. Gere dados sintÃ©ticos

```bash
# Gerar datasets de exemplo
python scripts/generate_synthetic_data.py

# Fazer upload para S3
python scripts/upload_to_s3.py
```

### 5. Execute o pipeline ETL completo

```bash
./scripts/run_pipeline.sh
```

Este script automaticamente:
- Faz upload do script Glue para S3
- Cria tabelas no Aurora (via Bastion Host se necessÃ¡rio)
- Verifica dados no S3 Raw
- Executa o Glue Job
- Monitora a execuÃ§Ã£o em tempo real

**Nota**: Se o Aurora estiver em subnet privada, vocÃª precisarÃ¡ criar as tabelas manualmente via Bastion Host:

```bash
# OpÃ§Ã£o 1: Script automÃ¡tico
./scripts/create_aurora_tables.sh

# OpÃ§Ã£o 2: Manual
# Terminal 1: Abrir tunnel SSH
./connect-aurora-alt.sh

# Terminal 2: Criar tabelas
psql -h localhost -p 15432 -U masteruser -d datawarehouse \
  -f scripts/glue_jobs/create_aurora_tables.sql
```



## Scripts DisponÃ­veis

| Script | DescriÃ§Ã£o |
|--------|-----------|
| `generate_synthetic_data.py` | Gera datasets sintÃ©ticos (escolas, alunos, notas) |
| `upload_to_s3.py` | Faz upload dos dados para S3 Raw |
| `run_pipeline.sh` | Executa o pipeline ETL completo (setup + job + monitoramento) |
| `create_aurora_tables.sh` | Cria tabelas no Aurora via tunnel SSH |
| `connect-aurora-alt.sh` | Abre tunnel SSH para Aurora (porta 15432) |
| `etl_pipeline.py` | Job Glue que processa dados e carrega no Aurora |
| `analytics_queries.sql` | Queries analÃ­ticas para anÃ¡lise de dados |
| `COST_OPTIMIZATION.md` | DocumentaÃ§Ã£o completa de otimizaÃ§Ã£o de custos |

## Limpeza

Para destruir toda a infraestrutura:

```bash
# Esvaziar buckets S3 primeiro
aws s3 rm s3://case-tec-dev-raw-letrus --recursive
aws s3 rm s3://case-tec-dev-processed-letrus --recursive
aws s3 rm s3://case-tec-dev-scripts-letrus --recursive

# Destruir infraestrutura
terraform destroy
```

